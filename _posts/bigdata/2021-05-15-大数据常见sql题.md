---
layout: post
title: 大数据常见sql题目汇总
categories: bigdata
tags: [sql, bigdata]
comments: true
---

# Table of Contents

- [Table of Contents](#table-of-contents)
- [分组topN](#分组topn)
- [次日留存](#次日留存)
- [连续登陆N天](#连续登陆n天)
- [换座位](#换座位)
- [最近30天内有互动的用户记录](#最近30天内有互动的用户记录)
- [求累计值](#求累计值)
  - [每天阅读不同文章最多的100人](#每天阅读不同文章最多的100人)
  - [每天阅读量和月初截至当天的累计阅读量](#每天阅读量和月初截至当天的累计阅读量)
  - [每个用户每天阅读量和每个用户月初截至当天的累计阅读量](#每个用户每天阅读量和每个用户月初截至当天的累计阅读量)
- [rows和range的区别](#rows和range的区别)
- [日期交叉问题](#日期交叉问题)
- [补充缺失日期和数据](#补充缺失日期和数据)
- [连续登录问题](#连续登录问题)

# 分组topN
<https://leetcode-cn.com/problems/department-top-three-salaries/>

    select
        Department.Name as Department,
        b.Name as Employee,
        Salary
    from(
        select
            Name,Salary,DepartmentId,
            dense_rank() over(partition by DepartmentId order by Salary desc) as `rank`
        from
            Employee
    ) b join Department on b.DepartmentId=Department.Id
    where
        `rank` <= N

# 次日留存
<https://leetcode.jp/problemdetail.php?id=1097>

    select
        install_date,
        count(distinct player_id) as install_uv,
        round(sum(if(datediff(event_date, install_date)=0, 1, 0))/count(distinct player_id), 2) as retention
    from(
        select
            player_id,
            event_date,
            min(event_date) over(partition by player_id order by event_date) as install_date
        from
            Activity
    ) b
    group by
        install_date

# 连续登陆N天
<https://blog.csdn.net/weixin_31960145/article/details/113320005>

    select
        uid,
        count(*) as 连续登陆天数,
        min(login_dt) as 第一天登陆日期,
        max(login_dt) as 最后一天登陆日期
    from(
        select
            uid,
            login_dt,
            date_sub(login_dt, row_number() over(partition by uid order by login_dt)) as dt
        from
            Login
    ) b
    group by
        uid,
        dt
    having count(*) >= N

# 换座位
<https://leetcode-cn.com/problems/exchange-seats/>

    select
        id,
        if(id%2=0, 
          lag(student, 1) over(order by id), -- 如果id是偶数，取上一行「lag」
          lead(student, 1, student) over(order by id) -- 如果id是奇数，取下一行，没有下一行时取自身「lead(field, 1, default)」
        ) as student
    from 
        seat

# 最近30天内有互动的用户记录

用户互动行为表tab
user1,
user2,
ts

a,b,    100
a,c,    120
b,d,    150

current_date=170

输出:
a,b,    100
b,d,    150
解释:
只有用户b和d在30天内有互动行为

    with base as(
        select
            user1,user2,ts,
            max(ts) over(partition by user1) as t1,
            max(ts) over(partition by user2) as t2
        from
            tab
    )
    select
        user1,user2,ts
    from
        base
    where
        date_diff(current_date, t1)<=30
        or date_diff(current_date, t2)<=30

# 求累计值
video_flow表

|:------|:------|:---------|
|用户|      文章|      阅读时间|
|uid|     cid|     read_time|

    with base as(
        select
            uid,
            aid,
            date_format(read_time, 'yyyyMMdd') as read_date,
            date_format(read_time, 'yyyyMM') as read_month,
            read_time
        from
            video_flw
    )

## 每天阅读不同文章最多的100人

    -- 每天阅读不同文章最多的100人
    select
        read_date,
        uid,
        read_rank
    from(
        select
            read_date,
            uid,
            row_number() over(partition by read_date order by count(distinct cid) desc) as read_rank
        from
            base
        group by
            read_date,
            uid
    ) b 
    where
        read_rank <= 100;

## 每天阅读量和月初截至当天的累计阅读量

    -- 每天阅读量和月初截至当天的累计阅读量
    select
        read_date,
        daily_read_cnt,
        sum(daily_read_cnt) over(partition by read_month order by read_date asc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as acc_read_cnt --累计阅读
    from(
        select
            read_date,
            read_month,
            count(*) as daily_read_cnt --天级阅读量
        from
            base
        group by
            read_date,
            read_month
    )b;

## 每个用户每天阅读量和每个用户月初截至当天的累计阅读量

    -- 每个用户每天阅读量和每个用户月初截至当天的累计阅读量
    select
        uid,
        read_date,
        daily_read_cnt,
        sum(daily_read_cnt) over(partition by uid,read_month order by read_date asc ROWS BETWEEN UNBOUNDED PRECEDING and CURRENT ROW) as acc_read_cnt --累计阅读
    from(
        select
            uid,
            read_date,
            read_month,
            count(*) as daily_read_cnt --天级阅读
        from
            base
        group by
            uid,
            read_date,
            read_month
    )b;

# rows和range的区别
[hive window](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics#LanguageManualWindowingAndAnalytics-LEADusingdefault1rowleadandnotspecifyingdefaultvalue)

[window specification](https://issues.apache.org/jira/secure/attachment/12575830/WindowingSpecification.pdf)

[sql window functions](https://www.sqltutorial.org/sql-window-functions/)


    select * from user order by name,age asc;
    +----+-----+----------+
    | id | age | name     |
    +----+-----+----------+
    | 14 | 1   | dapang   |
    | 22 | 1   | dapang   |
    | 15 | 2   | dapang   |
    | 23 | 2   | dapang   |
    | 19 | 6   | dapang   |
    | 20 | 7   | dapang   |
    | 16 | 3   | xiaopang |
    | 24 | 3   | xiaopang |
    | 17 | 4   | xiaopang |
    | 18 | 5   | xiaopang |
    +----+-----+----------+

    select
        id,
        name,
        age,
        sum(age) over() as a_sum, --窗口帧上下都无界，所有数据作为一个窗口
        sum(age) over(partition by name) as d_dum, --When both ORDER BY and WINDOW clauses are missing, the WINDOW specification defaults to ROW BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING. 窗口帧上下都无界，每个name作为一个窗口
        sum(age) over(partition by name order by age asc) as default_dum, --When ORDER BY is specified with missing WINDOW clause, the WINDOW specification defaults to RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. 与range_sum相同
        sum(age) over(partition by name order by age asc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as row_sum, --窗口帧按行号从第1行到当前行，每个name作为一个窗口
        sum(age) over(partition by name order by age asc RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as range_sum, --窗口帧按排序key从第1行到当前行，每个name作为一个窗口
        sum(age) over(partition by name order by age asc ROWS BETWEEN 1 PRECEDING AND 2 following) as row_sum1, --窗口帧按行号从前1行到后2行，每个name作为一个窗口
        sum(age) over(partition by name order by age asc RANGE BETWEEN 1 PRECEDING AND 2 following) as range_sum1 --窗口帧按排序key从前1行到后2行，每个name作为一个窗口
    from user
    order by
        name,
        age;
    +----+----------+-----+-------+-------+-------------+---------+-----------+----------+------------+
    | id | name     | age | a_sum | d_dum | default_dum | row_sum | range_sum | row_sum1 | range_sum1 |
    +----+----------+-----+-------+-------+-------------+---------+-----------+----------+------------+
    | 14 | dapang   | 1   | 34    | 19    | 2           | 1       | 2         | 4        | 6          |
    | 22 | dapang   | 1   | 34    | 19    | 2           | 2       | 2         | 6        | 6          |
    | 15 | dapang   | 2   | 34    | 19    | 6           | 4       | 6         | 11       | 6          |
    | 23 | dapang   | 2   | 34    | 19    | 6           | 6       | 6         | 17       | 6          |
    | 19 | dapang   | 6   | 34    | 19    | 12          | 12      | 12        | 15       | 13         |
    | 20 | dapang   | 7   | 34    | 19    | 19          | 19      | 19        | 13       | 13         |
    | 16 | xiaopang | 3   | 34    | 15    | 6           | 3       | 6         | 10       | 15         |
    | 24 | xiaopang | 3   | 34    | 15    | 6           | 6       | 6         | 15       | 15         |
    | 17 | xiaopang | 4   | 34    | 15    | 10          | 10      | 10        | 12       | 15         |
    | 18 | xiaopang | 5   | 34    | 15    | 15          | 15      | 15        | 9        | 9          |
    +----+----------+-----+-------+-------+-------------+---------+-----------+----------+------------+


# 日期交叉问题
```sql
-- 日期交叉问题
-- https://mp.weixin.qq.com/s?__biz=MzU5NTc1NzE2OA==&mid=2247484893&idx=1&sn=3147e75728bf905ec27ca2523f9b6239
CREATE TABLE `computer_promotion`(
    `brand` string COMMENT '用户主键',
    `start_date` string COMMENT '开始日期',
    `end_date` string COMMENT '结束日期'
);

insert into
    computer_promotion
values
    ('lenovo', '2022-02-03', '2022-02-07'),
    ('lenovo', '2022-02-10', '2022-02-23'),
    ('asus', '2022-02-08', '2022-02-24'),
    ('asus', '2022-02-13', '2022-02-17'),
    ('asus', '2022-02-15', '2022-02-28'),
    ('dell', '2022-02-04', '2022-02-17'),
    ('dell', '2022-02-07', '2022-02-21'),
    ('hp', '2022-02-06', '2022-02-26'),
    ('hp', '2022-02-08', '2022-02-19'),
    ('hp', '2022-02-15', '2022-02-23');

-- 根据表数据求出每种电脑品牌促销的天数
select
    brand,
    sum(datediff(end_date, start_date) + 1) --过滤掉开始日期大于结束日期的数据，并且根据品牌分组，对每条记录的结束和开始日期求日期差+1，然后求sum， 获得最终结果
from
    (
        select
            brand,
            --比较此次促销开始日期与步骤一获得的结束日期，如果开始日期比结束日期小或者相等，那么以步骤一获得的日期加一天作为此次促销的开始日期，反之，记当前记录的开始end_date, 日期为本次促销的开始
            if(
                start_date <= max_edd,
                date_add(max_edd, 1),
                start_date
            ) as start_date,
            end_date
        from
            (
                select
                    brand,
                    start_date,
                    end_date,
                    max(end_date) over(
                        partition by brand
                        order by
                            start_date rows between unbounded preceding
                            and 1 preceding
                    ) max_edd --采用max窗口函数，根据开始日期正序，获得此次促销记录之前最大的促销结束日期
                from
                    computer_promotion
            )
    )
where
    start_date < end_date
group by
    brand;
```


# 补充缺失日期和数据

```sql
-- 补充缺失日期和数据
-- https://mp.weixin.qq.com/s/05r_XJ9CjnJFyeZU3TChCw
CREATE TABLE `product`(
    `name` string comment "名称",
    `dt` string comment "日期",
    `amount` int comment "销售金额"
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';

insert into
    product
values
    ('iphone', '2023-02-03', 100),
    ('iphone', '2023-02-05', 300),
    ('iphone', '2023-02-08', 150),
    ('mac', '2023-02-01', 200),
    ('mac', '2023-02-02', 400),
    ('mac', '2023-02-06', 700),
    ('airpods', '2023-02-02', 300),
    ('airpods', '2023-02-04', 200),
    ('airpods', '2023-02-07', 100),
    ('airpods', '2023-02-11', 400);

select
    name,
    --利用date_add函数和posexplode函数展开的索引获取相应日期，且把本行的amount数据补充上
    date_add(dt, col_idx) as dt,
    amount
from
    (
        select
            name,
            dt,
            amount,
            lead(dt, 1, dt) over(
                partition by name
                order by
                    dt
            ) next_dt --利用窗口函数lead,补充同一组的下一个日期
        from
            product
    ) tmp lateral view posexplode(split(space(datediff(next_dt, dt)), ' (?!$)')) tbl_idx as col_idx,
    --根据当前的日期和和补充的下一个日期，利用space/split等函数构建posexplde数据展开
    col_val;

select
    posexplode(split(space(4), ' (?!$)'));

-- 0
-- 1
-- 2
-- 3
select
    posexplode(split(space(4), ' '));

-- 0
-- 1
-- 2
-- 3
-- 4
```

# 连续登录问题

```sql
-- 连续登录问题
CREATE TABLE `user_login`(
   `id` int COMMENT '用户主键',
   `dt` string COMMENT '登录日期'
);
insert into
   user_login
values
   (1001, '2021-12-12'),
   (1002, '2021-12-12'),
   (1001, '2021-12-13'),
   (1001, '2021-12-14'),
   (1001, '2021-12-16'),
   (1002, '2021-12-16'),
   (1001, '2021-12-19'),
   (1002, '2021-12-17'),
   (1001, '2021-12-20');
-- 求出连续3天登录的用户id
select
   distinct id
from
   (
       select
           id,
           dt,
           pre_2_dt,
           datediff(dt, pre_2_dt) as diff
       from
           (
               select
                   id,
                   dt,
                   lag (dt, 2, '0000-00-00') over(
                       partition by id
                       order by
                           dt
                   ) as pre_2_dt
               from
                   user_login
           )
   )
where
   diff = 2;

-- 中间间隔一天，也算连续登录，求出连续4天登录的用户id
-- 1：利用lag（lead） 比较当前日期与上一次登录日期的差
-- 2：如果日期差小于等于2，则连续登录，记为0，否则记为1，为日期基准
-- 3：利用窗口函数sum，获取用户到当前行的和
-- 4：连续登录用户步骤三求和结果相同（+0）
-- 5：根据用户和步骤三求得的分组基准分组，并过滤出连续登录超过4天的用户
-- 6：根据用户分组去重，获得结果
select
   distinct id
from
   (
       select
           id,
           dt,
           pre_1_dt,
           datediff(dt, pre_1_dt) as diff,
           sum(if(datediff(dt, pre_1_dt) <= 2, 0, 1)) over(
               partition by id
               order by
                   dt
           ) as base
       from
           (
               select
                   id,
                   dt,
                   lag (dt, 1, '0000-00-00') over(
                       partition by id
                       order by
                           dt
                   ) as pre_1_dt
               from
                   user_login
           )
   )
group by
   id,
   base
HAVING
   count(1) >= 4;
```