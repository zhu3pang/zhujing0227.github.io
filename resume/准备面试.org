* Java 
** HashMap
*** 如何找到比设置的初始容量值大的最小的 2 的幂次方整数
#+BEGIN_SRC java
static final int tableSizeFor(int cap) {
						//01xxxx xxxxxxxx xxxxxxxx xxxxxxxx
    int n = cap - 1;	//001xxx xxxxxxxx xxxxxxxx xxxxxxxx
    n |= n >>> 1;		//0011xx xxxxxxxx xxxxxxxx xxxxxxxx	把 n 的最高位为 1 的紧邻的右边的 1 位也置为了 1，这样高位中有连续两位都是 1
    n |= n >>> 2;		//001111 xxxxxxxx xxxxxxxx xxxxxxxx	n 的高位中有连续 4 个 1
    n |= n >>> 4;		//001111 1111xxxx xxxxxxxx xxxxxxxx	n 的高位中有连续 8 个 1
    n |= n >>> 8;		//001111 11111111 1111xxxx xxxxxxxx	n 的高位中有连续 16 个 1
    n |= n >>> 16;		//001111 11111111 11111111 11111111	n 的高位1后面都置为 1
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;//010000 00000000 00000000 00000000	+1 后就相当于找比这个数大的最小的 2的整数次幂
}
#+END_SRC
*** HashMap 中对 key 做 hash 处理时，做了什么特殊操作？为什么这么做
#+BEGIN_SRC java
static final int hash(Object key) {
    int h;
    return (key == null) 
    ? 0 
    : (h = key.hashCode()) ^ (h >>> 16);//hashcode右移 16位后再进行异或操作，然后计算其对应的数组下标后，就被分到了不同的桶中，解决了哈希碰撞问题，思想就是把高位和低位混合进行计算，提高分散性
}
#+END_SRC
*** put 操作分析
#+BEGIN_SRC java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;    // 1.初始化数组,高并发下在这里可能会丢失数据
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);//2.索引 i=(n-1)&hash 位置处为空, 创建新节点
    else {
        //索引 i=(n-1)&hash 位置处不为空, 在该链表里处理要新增的元素
        Node<K,V> e;/*记录新增元素待插入的位置*/ K k;
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;//3.key 相同, 覆盖
        else if (p instanceof TreeNode)//红黑树新增
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            //链表新增
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {//4.找到要新增的位置,尾插
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);//链表转红黑树
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;//5.key 与链表中的元素相同, 覆盖
                p = e;
            }
        }
        if (e != null) { // existing mapping for key, 6.e!=null 说明有 hash 冲突, e 即为要覆盖的位置
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
#+END_SRC
*** get 操作分析
#+BEGIN_SRC java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {//1.(n - 1) & hash 找到 key 所在的位置
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;//2.hash 相等并且 key 是一样的,直接返回头结点
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)//3.红黑树查找 O(logN)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do {//4.先序遍历链表 O(N)
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
#+END_SRC
*** resize 操作分析
#+BEGIN_SRC java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {//1.旧的 size 太大了, 直接返回原数组
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;//2.计算新数据的容量及阈值
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;// 3.初始化新的数组
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {//rehash
            Node<K,V> e;//4.下面是每个桶重新分配位置
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order // 链表优化重hash的代码块
                    //声明两对指针，维护两个连链表依次在末端添加新的元素。(在多线程操作的情况下，无非是第二个线程重复第一个线程一模一样的操作)
                    //1.8中hashmap的确不会因为多线程put导致死循环
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        // 原索引
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 原索引+oldCap
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 原索引放到bucket里
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 原索引+oldCap放到bucket里
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
#+END_SRC
#+begin_example
[[https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/4d8022db.png][扩容前后key1和key2两种key确定索引位置]]
#+end_example
** ConcurrentHashMap
https://swenfang.github.io/2018/06/03/Java%208%20ConcurrentHashMap%20%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/
*** volatile
一旦一个共享变量(类的成员变量、类的静态成员变量)被 volatile 修饰之后, 那么就具备
了两个语义:
1. 保证了不同线程对这个变量 进行操作时的[[内存可见性][可见性]], 即一个线程修改了某个变量的
 值,这新值对其他线程是立即可见的;
2. 禁止进行指令重排
 
使用 volatile 必须具备以下两个条件:
1. 对变量的写入操作不依赖变量的当前值,或者能确保只有单个线程更新变量的值;
2. 该变量没有包含在具有其他变量的不变式中.
**** 内存可见性
由于 Java 内存模型(JMM)规定，所有的变量都存放在主内存中，而每个线程都有着自己的工
作内存(高速缓存)；线程在工作时，需要将主内存中的数据拷贝到工作内存中。这样对数据
的任何操作都是基于工作内存(效率提高)，并且不能直接操作主内存以及其他线程工作内存
中的数据，之后再将更新之后的数据刷新到主内存中；
1. 这里所提到的主内存可以简单认为是堆内存，而工作内存则可以认为是栈内存；
2. 当一个变量被 volatile 修饰时，任何线程对它的写操作都会立即刷新到主内存中，并
   且会强制让缓存了该变量的线程中的数据清空，必须从主内存重新读取最新数据；
3. volatile 修饰之后并不是让线程直接从主内存中获取数据，依然需要将变量拷贝到工作内存中；
*** CAS 操作
CAS 一般被理解为原子操作。在 java 中，正是利用了处理器的 CMPXCHG（intel）指令实现 CAS
操作。CAS 需要接受原有期望值 expected 以及想要修改的新值 x，只有在原有期望值与当前值
相等时才会更新为 x，否则为失败。在 ConcurrentHashMap 的方法中，大量使用 CAS 获取/修改
互斥量，以达到多线程并发环境下的正确性
*** put 操作分析
1. 首先对于每一个放入的值，首先利用 spread 方法对 key 的 hashcode 进行一次 hash 计算，由
   此来确定这个值在 table 中的位置；
2. 如果当前 table 数组还未初始化，先将 table 数组进行初始化操作；
3. 如果这个位置是 null 的，那么使用 CAS 操作直接放入；
4. 如果这个位置存在结点，说明发生了 hash 碰撞，首先判断这个节点的类型。如果该节点
   fh==MOVED(代表 forwardingNode,数组正在进行扩容)的话，说明正在进行扩容；
5. 如果是链表节点（fh>0）,则得到的结点就是 hash 值相同的节点组成的链表的头节点。需
   要依次向后遍历确定这个新加入的值所在位置。如果遇到 hash 值与 key 值都与新加入节点
   是一致的情况，则只需要更新 value 值即可。否则依次向后遍历，直到链表尾插入这个结
   点；
6. 如果这个节点的类型是 TreeBin 的话，直接调用红黑树的插入方法进行插入新的节点；
7. 插入完节点之后再次检查链表长度，如果长度大于 8，就把这个链表转换成红黑树；
8. 对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容。
#+BEGIN_SRC java
  final V putVal(K key, V value, boolean onlyIfAbsent) {
      // 不允许 key 和 value 为空
      if (key == null || value == null) throw new NullPointerException();
      // 1.计算 key 的 hash 值(计算新节点的hash值)
      int hash = spread(key.hashCode()); // 返回 (h^(h>>>16))&HASH_BITS
      int binCount = 0;
      // 获取当前table，进入死循环,直到插入成功！
      for (Node<K,V>[] tab = table;;) { 
          Node<K,V> f; int n, i, fh;
          // 2. 如果当前 table 还没初始化先调用 initTable 方法将 tab 进行初始化
          if (tab == null || (n = tab.length) == 0)
              tab = initTable(); // 如果table为空，执行初始化，也即是延迟初始化
          // 3. tab中索引为i的位置的元素为null,则直接使用 CAS 将值插入即可
          // 如果bin为空，则采用cas算法赋值，无需加锁
          else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
              if (casTabAt(tab, i, null,new Node<K,V>(hash, key, value, null)))
                  // 直接设置为桶首节点成功，退出死循环（出口之一）
                  break;              
          }
          // 4. 当前正在扩容
          // 当前桶首节点正在特殊的扩容状态下，当前线程尝试参与扩容
          // 然后重新进入死循环
          //f.hash == MOVED 表示为：ForwardingNode，说明其他线程正在扩容
          else if ((fh = f.hash) == MOVED) // MOVED = -1 
              tab = helpTransfer(tab, f); // 当发现其他线程扩容时，帮其扩容
         // 通过桶首节点，将新节点加入table
          else {
              V oldVal = null;
              // 获取桶首节点实例对象锁，进入临界区进行添加操作
              synchronized (f) {
                  // 再判断以此f是否仍是第一个Node，如果不是，退出临界区，重复添加操作
                  if (tabAt(tab, i) == f) {
                      //5. 当前为链表，在链表中插入新的键值对
                      if (fh >= 0) { // 桶首节点hash值>0，表示为链表
                          binCount = 1;
                          for (Node<K,V> e = f;; ++binCount) {
                              K ek;
                              // 找到hash值相同的key,覆盖旧值即可
                              if (e.hash == hash &&
                                  ((ek = e.key) == key ||
                                   (ek != null && key.equals(ek)))) {
                                  oldVal = e.val;
                                  // 仅 putIfAbsent() 方法中的 onlyIfAbsend 为 true;
                                  if (!onlyIfAbsent)
                                      // putIfAbsend() 包含 key 则返回 get ,否则 put 并返回
                                      e.val = value; 
                                  break;
                              }
                              Node<K,V> pred = e;
                              //如果到链表末尾仍未找到，则直接将新值插入到链表末尾即可
                              if ((e = e.next) == null) {
                                  pred.next = new Node<K,V>(hash, key,
                                                            value, null);
                                  break;
                              }
                          }
                      }
                      // 桶首节点为Node子类型TreeBin，表示为红黑树
                      // 6.当前为红黑树，将新的键值对插入到红黑树中
                      else if (f instanceof TreeBin) {
                          Node<K,V> p;
                          binCount = 2;
                          // 调用putTreeVal方法，插入新值
                          if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                         value)) != null) {
                              // key已经存在，则替换
                              oldVal = p.val;
                              if (!onlyIfAbsent)
                                  p.val = value;
                          }
                      }
                  }
              }
               // 7.插入完键值对后再根据实际大小看是否需要转换成红黑树
              if (binCount != 0) {
                  if (binCount >= TREEIFY_THRESHOLD)
                      // 插入新节点后，达到链表转换红黑树阈值，则执行转换操作
                      // 此函数内部会判断是树化，还是扩容：tryPresize
                      treeifyBin(tab, i);
                  // 退出死循环（出口之二）
                  if (oldVal != null)
                      return oldVal;
                  break;
              }
          }
      }
      // 更新计算count时的base和counterCells数组
      //8.对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容 
      addCount(1L, binCount);
      return null;
  }
#+END_SRC
*** get 操作分析
e = tabAt(tab, (n - 1) & h)) != null, tabAt 用了 Unsafe 的 getObjectVolatile，对
volatile 域的写入操作 happens-before 于每一个后续对同一域的读操作。所以不管其他线程
对 table 链表或树的修改，都对 get 读取可见。
#+BEGIN_SRC java
  public V get(Object key) {
      Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
       // 1. 重hash
      int h = spread(key.hashCode());

      // 2. table[i]桶节点的key与查找的key相同，则直接返回
      if ((tab = table) != null && (n = tab.length) > 0 &&
          // 唯一一处volatile读操作
          (e = tabAt(tab, (n - 1) & h)) != null) {  
          // 注意：因为容器大小为2的次方，所以 h mod n = h & (n -1)
      
          if ((eh = e.hash) == h) {// 如果hash值相等
              // 检查第一个Node
              if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                  return e.val;
          }
          // hash为负表示是扩容中的ForwardingNode节点
          // 直接调用ForwardingNode的find方法(可以是代理到扩容中的nextTable)
          // 3. 当前节点hash小于0说明为树节点，在红黑树中查找即可
          else if (eh < 0)
              return (p = e.find(h, key)) != null ? p.val : null;
          // 遍历链表，对比key值
          // 通过next指针，逐一查找
          while ((e = e.next) != null) {
              //4. 从链表中查找，查找到则返回该节点的value，否则就返回null即可
              if (e.hash == h &&
                  ((ek = e.key) == key || (ek != null && key.equals(ek))))
                  return e.val;
          }
      }
      return null;
  }
#+END_SRC
*** transfer 操作分析
1. 构建一个 nextTable,它的容量是原来的两倍，这个操作是单线程完成的。新建 table 数组
   的代码为:Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1],在原容量大小的基
   础上右移一位。
2. 将原来 table 中的元素复制到 nextTable 中，主要是遍历复制的过程。根据运算得到当前
   遍历的数组的位置 i，然后利用 tabAt 方法获得 i 位置的元素再进行判断：
   - 如果这个位置为空，就在原 table 中的 i 位置放入 forwardNode 节点，这个也是触发并发扩容的关键点；
   - 如果这个位置是 Node 节点（fh>=0），如果它是一个链表的头节点，就构造一个反序链
     表，把他们分别放在 nextTable 的 i 和 i+n 的位置上
   - 如果这个位置是 TreeBin 节点（fh<0），也做一个反序处理，并且判断是否需要
     untreefi，把处理的结果分别放在 nextTable 的 i 和 i+n 的位置上
   - 遍历过所有的节点以后就完成了复制工作，这时让 nextTable 作为新的 table，并且更
     新 sizeCtl 为新容量的 0.75 倍 ，完成扩容。设置为新容量的 0.75 倍代码为 sizeCtl =
     (n << 1) - (n >>> 1)，仔细体会下是不是很巧妙，n<<1 相当于 n 右移一位表示 n 的两
     倍即 2n,n>>>1 左右一位相当于 n 除以 2 即 0.5n,然后两者相减为 2n-0.5n=1.5n,是不是刚
     好等于新容量的 0.75 倍即 2n*0.75=1.5n。
#+BEGIN_SRC java
  private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
      int n = tab.length, stride;
      //计算每次迁移的node个数（MIN_TRANSFER_STRIDE该值作为下限，以避免扩容线程过多）
      if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
          // 确保每次迁移的node个数不少于16个
          stride = MIN_TRANSFER_STRIDE; 
      // nextTab为扩容中的临时table
      if (nextTab == null) {
          try {
              //扩容一倍  
              @SuppressWarnings("unchecked")
              // 1. 新建一个 node 数组，容量为之前的两倍
              Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
              nextTab = nt;
          } catch (Throwable ex) {      // try to cope with OOME
              sizeCtl = Integer.MAX_VALUE;
              return;
          }
          nextTable = nextTab;
          // transferIndex为扩容复制过程中的桶首节点遍历索引
          // 所以从n开始，表示从后向前遍历
          transferIndex = n;
      }
      int nextn = nextTab.length;
      // ForwardingNode是Node节点的直接子类，是扩容过程中的特殊桶首节点
      // 该类中没有key,value,next
      // hash值为特定的-1
      // 附加Node<K,V>[] nextTable变量指向扩容中的nextTab
      // 在find方法中，将扩容中的查询操作导入到nextTab上
      //2. 新建forwardingNode引用，在之后会用到
      ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
      boolean advance = true;
      // 循环的关键变量，判断是否已经扩容完成，完成就 return , 退出循环
      boolean finishing = false; 
       //【1】逆序迁移已经获取到的hash桶集合，如果迁移完毕，则更新transferIndex，
       // 获取下一批待迁移的hash桶
       //【2】如果transferIndex=0，表示所以hash桶均被分配，将i置为-1，
      // 准备退出transfer方法
      for (int i = 0, bound = 0;;) {
          Node<K,V> f; int fh;
          // 3. 确定遍历中的索引i（更新待迁移的hash桶索引）
          // 循环的关键 i , i-- 操作保证了倒叙遍历数组
          while (advance) {
              int nextIndex, nextBound;
              // 更新迁移索引i
              if (--i >= bound || finishing)
                  advance = false;
              // transferIndex = 0表示table中所有数组元素都已经有其他线程负责扩容
              // nextIndex=transferIndex=n=tab.length(默认16)
              else if ((nextIndex = transferIndex) <= 0) {
                  // transferIndex<=0表示已经没有需要迁移的hash桶，
                  // 将i置为-1，线程准备退出
                  i = -1;
                  advance = false;
              }
           //cas无锁算法设置 transferIndex = transferIndex - stride     
           // 尝试更新transferIndex，获取当前线程执行扩容复制的索引区间
           // 更新成功，则当前线程负责完成索引为(nextBound，nextIndex)之间的桶首节点扩容
           //当迁移完bound这个桶后，尝试更新transferIndex，获取下一批待迁移的hash桶
              else if (U.compareAndSwapInt
                       (this, TRANSFERINDEX, nextIndex,
                        nextBound = (nextIndex > stride ?
                                     nextIndex - stride : 0))) {
                  bound = nextBound;
                  i = nextIndex - 1;
                  advance = false;
              }
          } //退出transfer
          //4.将原数组中的元素复制到新数组中去
          //4.5 for循环退出，扩容结束修改sizeCtl属性
  // i<0 说明已经遍历完旧的数组tab;i>=n什么时候有可能呢？在下面看到i=n,所以目前i最大应该是n吧
  // i+n>=nextn,nextn=nextTab.length,所以如果满足i+n>=nextn说明已经扩容完成
          if (i < 0 || i >= n || i + n >= nextn) {
              int sc;
              if (finishing) {   // a
                  //最后一个迁移的线程，recheck后，做收尾工作，然后退出
                  nextTable = null;
                  table = nextTab;
                  // 扩容成功，设置新sizeCtl，仍然为总大小的0.75
                  sizeCtl = (n << 1) - (n >>> 1);
                  return;
              }
        
              // 第一个扩容的线程，执行transfer方法之前，会设置 sizeCtl = 
              // (resizeStamp(n) << RESIZE_STAMP_SHIFT) + 2)  
              // 后续帮其扩容的线程，执行transfer方法之前，会设置 sizeCtl = sizeCtl+1
              // 每一个退出transfer的方法的线程，退出之前，会设置 sizeCtl = sizeCtl-1
              // 那么最后一个线程退出时：
              // 必然有sc == (resizeStamp(n) << RESIZE_STAMP_SHIFT) + 2)，
              // 即 (sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT
          
              if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {                  
                  // 如果有多个线程进行扩容，那么这个值在第二个线程以后就不会相等，因为 
                  // sizeCtl 已经被减1了，所以后面的线程只能直接返回，
                  // 始终保证只有一个线程执行了a(上面的注释a)
                  if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
                      return;
                  // finishing 和 advance 保证线程已经扩容完成了可以退出循环
                  finishing = advance = true;
                  //最后退出的线程要重新check下是否全部迁移完毕
                  i = n;
              }
          }
          // 当前table节点为空，不需要复制，直接放入ForwardingNode
          //4.1 当前数组中第i个元素为null，用CAS设置成特殊节点forwardingNode(可以理解成占位符)
          // 如果 tab[i] 为 null,那么就把 fwd 插入到 tab[i],表明这个节点已经处理过了
          else if ((f = tabAt(tab, i)) == null)
              advance = casTabAt(tab, i, null, fwd);
          // 当前table节点已经是ForwardingNode
          // 表示已经被其他线程处理了，则直接往前遍历
          // 通过CAS读写ForwardingNode节点状态，达到多线程互斥处理
          // 4.2 如果遍历到ForwardingNode节点说明这个点已经被处理过了直接跳过
          // 这里是控制并发扩容的核心
          // 如果 f.hash=-1 的话说明该节点为 ForwardingNode,说明该节点已经处理过了
          else if ((fh = f.hash) == MOVED)
              advance = true; 
          //迁移node节点
          else {
              // 锁住当前桶首节点
              synchronized (f) {
                  if (tabAt(tab, i) == f) {
                      Node<K,V> ln, hn;
                      // 链表节点复制(链表迁移)
                      if (fh >= 0) {
                      // 4.3 处理当前节点为链表的头结点的情况，构造两个链表，一个是原链表  
                      // 另一个是原链表的反序排列
                          int runBit = fh & n;
                          Node<K,V> lastRun = f;
              //将node链表，分成2个新的node链表
              // 这边还对链表进行遍历，这边的算法和hashMap的算法又不一样了，对半拆分
              // 把链表拆分为，hash&n 等于0和不等于0的，然后分别放在新表的i和i+n位置             
              // 此方法同 HashMap 的 resize
                          for (Node<K,V> p = f.next; p != null; p = p.next) {
                              int b = p.hash & n;
                              if (b != runBit) {
                                  runBit = b;
                                  lastRun = p;
                              }
                          }
                          if (runBit == 0) {
                              ln = lastRun;
                              hn = null;
                          }
                          else {
                              hn = lastRun;
                              ln = null;
                          }
                          for (Node<K,V> p = f; p != lastRun; p = p.next) {
                              int ph = p.hash; K pk = p.key; V pv = p.val;
                              if ((ph & n) == 0)
                                  ln = new Node<K,V>(ph, pk, pv, ln);
                              else
                                  hn = new Node<K,V>(ph, pk, pv, hn);
                          }
                          //将新node链表赋给nextTab
                          //在nextTable的i位置上插入一个链表
                          setTabAt(nextTab, i, ln);
                          //在nextTable的i+n的位置上插入另一个链表
                          setTabAt(nextTab, i + n, hn);
                          // 扩容成功后，设置ForwardingNode节点
                          //在table的i位置上插入forwardNode节点表示已经处理过该节点
                          // 把已经替换的节点的旧tab的i的位置用fwd替换，fwd包含nextTab
                          setTabAt(tab, i, fwd);
                          //设置advance为true 返回到上面的while循环中 就可以执行i--操作
                          advance = true;
                      }
                      // 红黑树节点复制(红黑树迁移)
                      //4.4 处理当前节点是TreeBin时的情况，操作和上面的类似
                      else if (f instanceof TreeBin) {
                          TreeBin<K,V> t = (TreeBin<K,V>)f;
                          TreeNode<K,V> lo = null, loTail = null;
                          TreeNode<K,V> hi = null, hiTail = null;
                          int lc = 0, hc = 0;
                          for (Node<K,V> e = t.first; e != null; e = e.next) {
                              int h = e.hash;
                              TreeNode<K,V> p = new TreeNode<K,V>
                                  (h, e.key, e.val, null, null);
                              if ((h & n) == 0) {
                                  if ((p.prev = loTail) == null)
                                      lo = p;
                                  else
                                      loTail.next = p;
                                  loTail = p;
                                  ++lc;
                              }
                              else {
                                  if ((p.prev = hiTail) == null)
                                      hi = p;
                                  else
                                      hiTail.next = p;
                                  hiTail = p;
                                  ++hc;
                              }
                          }
                          // 判断扩容后是否还需要红黑树
                          ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                              (hc != 0) ? new TreeBin<K,V>(lo) : t;
                          hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                              (lc != 0) ? new TreeBin<K,V>(hi) : t;
                          setTabAt(nextTab, i, ln);
                          setTabAt(nextTab, i + n, hn);
                          // 扩容成功后，设置ForwardingNode节点
                          setTabAt(tab, i, fwd);
                          advance = true;
                      }
                  }
              }
          }
      }
  }
#+END_SRC
*** initTable 操作分析
若当前已经有一个线程正在初始化即 sizeCtl 值变为-1，这个时候其他线程在 If 判断为 true
从而调用 Thread.yield()让出 CPU 时间片。正在进行初始化的线程会调用
U.compareAndSwapInt 方法将 sizeCtl 改为-1 即正在初始化的状态。
#+BEGIN_SRC java
  private final Node<K,V>[] initTable() {
      Node<K,V>[] tab; int sc;
      while ((tab = table) == null || tab.length == 0) {
          // 前文提及sizeCtl是重要的控制变量
          // sizeCtl = -1 表示正在初始化
          if ((sc = sizeCtl) < 0)
              // 已经有其他线程在执行初始化，则主动让出cpu
              // 1. 保证只有一个线程正在进行初始化操作
              Thread.yield();
      
          // 利用CAS操作设置sizeCtl为-1
          // 设置成功表示当前线程为执行初始化的唯一线程
          // 此处进入临界区
          else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
              try {
                  // 由于让出cpu的线程也会后续进入该临界区
                  // 需要进行再次确认table是否为null
                  if ((tab = table) == null || tab.length == 0) {
                      // 2. 得出数组的大小
                      int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                      @SuppressWarnings("unchecked")
                      // 3. 这里才真正的初始化数组，即分配Node数组
                      Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                      table = tab = nt;
                      // 默认负载为0.75
                      // 4. 计算数组中可用的大小：实际大小n*0.75（加载因子）
                      sc = n - (n >>> 2);
                  }
              } finally {
                  sizeCtl = sc;
              }
              // 退出死循环的唯一出口
              break;
          }
      }
      return tab;
  }
#+END_SRC
** CopyOnWriteArrayList
CopyOnWrite 容器也是一种读写分离的思想，延时更新的策略是通过在写的时候针对的是不
同的数据容器来实现的，放弃数据实时性达到数据的最终一致性。
#+BEGIN_SRC java
  public boolean add(E e) {
      final ReentrantLock lock = this.lock;
      //1. 使用Lock,保证写线程在同一时刻只有一个
      lock.lock();
      try {
          //2. 获取旧数组引用
          Object[] elements = getArray();
          int len = elements.length;
          //3. 创建新的数组，并将旧数组的数据复制到新数组中
          Object[] newElements = Arrays.copyOf(elements, len + 1);
          //4. 往新数组中添加新的数据
          newElements[len] = e;
          //5. 将旧数组引用指向新的数组
          setArray(newElements);
          return true;
      } finally {
          lock.unlock();
      }
  }
#+END_SRC
***  优点
 1. 数据一致性完整，为什么？因为加锁了，并发数据不会乱
 2. 解决了像 ArrayList、Vector 这种集合多线程遍历迭代问题，记住，Vector 虽然线程安
    全，只不过是加了 synchronized 关键字，迭代问题完全没有解决
*** 缺点
 1. 耗内存(写时复制)
 2. 数据一致性延迟
*** 使用场景
 1. 读多写少（白名单，黑名单，商品类目的访问和更新场景），为什么？因为写的时候会
    复制新集合
 2. 集合不大，为什么？因为写的时候会复制新集合
 3. 实时性要求不高，为什么，因为有可能会读取到旧的集合数据
** ThreadPoolExecutor
1. 调用 ThreadPoolExecutor 的 execute 提交线程，首先检查 CorePool，如果 CorePool 内的线
   程小于 CorePoolSize，新创建线程执行任务。
2. 如果当前 CorePool 内的线程大于等于 CorePoolSize，那么将线程加入到 BlockingQueue。
3. 如果不能加入 BlockingQueue，在小于 MaxPoolSize 的情况下创建线程执行任务。
4. 如果线程数大于等于 MaxPoolSize，那么执行拒绝策略。
*** 线程池的创建
1. corePoolSize  核心线程池大小
2. maximumPoolSize  线程池最大容量
3. keepAliveTime 线程存活时间
4. unit 时间单位
5. workQueue 工作任务队列
6. threadFactory 线程工厂
7. handler 拒绝策略
   - AbortPolicy 抛异常,拒绝
   - DiscardPolicy 什么都不做,丢弃
   - DiscardOldestPolicy 丢弃最老的任务
   - CallerRunsPolicy 在当前线程执行任务
#+BEGIN_SRC java
  public ThreadPoolExecutor(int corePoolSize,
                            int maximumPoolSize,
                            long keepAliveTime,
                            TimeUnit unit,
                            BlockingQueue<Runnable> workQueue,
                            ThreadFactory threadFactory,
                            RejectedExecutionHandler handler) {
      if (corePoolSize < 0 ||
          maximumPoolSize <= 0 ||
          maximumPoolSize < corePoolSize ||
          keepAliveTime < 0)
          throw new IllegalArgumentException();
      if (workQueue == null || threadFactory == null || handler == null)
          throw new NullPointerException();
      this.corePoolSize = corePoolSize;
      this.maximumPoolSize = maximumPoolSize;
      this.workQueue = workQueue;
      this.keepAliveTime = unit.toNanos(keepAliveTime);
      this.threadFactory = threadFactory;
      this.handler = handler;
  }
#+END_SRC
**** allowCoreThreadTimeOut
1. false. default core threads stay alive even when idle.
2. true. core threads use keepAliveTime to time out waiting for work.
允许核心线程超过空闲时间被销毁
**** prestartAllCoreThreads & prestartCoreThread
By default, even core threads are initially created and
started only when new tasks arrive, but this can be overridden
dynamically using method {@link #prestartCoreThread} or {@link
#prestartAllCoreThreads}.  You probably want to prestart threads if
you construct the pool with a non-empty queue.
预创建核心线程
***  线程池状态
[[./images/threadpoolexecutor状态转移.png][状态转移图]]
#+BEGIN_SRC java
  private static final int COUNT_BITS = Integer.SIZE - 3;
  private static final int CAPACITY   = (1 << COUNT_BITS) - 1;
  // runState is stored in the high-order bits
  private static final int RUNNING    = -1 << COUNT_BITS; //运行状态，可以添加新任务，也可以处理阻塞队列中的任务。
  private static final int SHUTDOWN   =  0 << COUNT_BITS; //待关闭状态，不再接受新的任务，会继续处理阻塞队列中的任务。 
  private static final int STOP       =  1 << COUNT_BITS; //停止状态，不再接受新的任务，不会执行阻塞队列中的任务，打断正在执行的任务。 
  private static final int TIDYING    =  2 << COUNT_BITS; //整理状态，所有任务都处理完毕，workerCount为0，线程转到该状态将会运行terminated()钩子方法。
  private static final int TERMINATED =  3 << COUNT_BITS; //终止状态，terminated()方法执行完毕。
  // Packing and unpacking ctl
  private static int runStateOf(int c)     { return c & ~CAPACITY; }
  private static int workerCountOf(int c)  { return c & CAPACITY; }
  private static int ctlOf(int rs, int wc) { return rs | wc; }
#+END_SRC
** ThreadLocal
http://www.jasongj.com/java/threadlocal/
1. ThreadLocal 并不是用来解决线程间共享数据的问题;
2. ThreadLocal 通过隐式的在不同线程内创建独立实例副本避免了实例线程安全的问题;
3. 每个线程持有一个 ThreadLocalMap, 并维护了 ThreadLocal 对象与具体实例的映射, 该
   ThreadLocalMap 由于只被持有它的线程访问, 故不存在线程安全及锁的问题;
4. ThreadLocalMap 的 Entry 对 ThreadLocal 的引用为弱引用, 避免了 ThreadLocal 对象
   无被回收的问题;
5. ThreadLocalMap 的 set 方法通过 replaceStaleEntry 方法回收键为 null 的 Entry 对
   象的值(即具体的实例)以及 Entry 对象本身从而防止内存泄漏;
6. ThreadLocal 适用于在线程间隔离
***  设置实例
该方法先获取该线程的 ThreadLocalMap 对象，然后直接将 ThreadLocal 对象（即代码中
的 this）与目标实例的映射添加进 ThreadLocalMap 中。当然，如果映射已经存在，就直
接覆盖。另外，如果获取到的 ThreadLocalMap 为 null，则先创建该 ThreadLocalMap 对
象。
#+BEGIN_SRC java
  public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
      map.set(this, value);
    else
      createMap(t, value);
  }
#+END_SRC
***  读取实例
获取到 ThreadLocalMap 后，通过 map.getEntry(this)方法获取该 ThreadLocal 在当前线
程的 ThreadLocalMap 中对应的 Entry。该方法中的 this 即当前访问的 ThreadLocal 对
象。

如果获取到的 Entry 不为 null，从 Entry 中取出值即为所需访问的本线程对应的实例。
如果获取到的 Entry 为 null，则通过 setInitialValue()方法设置该 ThreadLocal 变量在
该线程中对应的具体实例的初始值。
#+BEGIN_SRC java
  public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
      ThreadLocalMap.Entry e = map.getEntry(this);
      if (e != null) {
        @SuppressWarnings("unchecked")
        T result = (T)e.value;
        return result;
      }
    }
    return setInitialValue();
  }
  ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
  }
#+END_SRC
*** 防止内存泄漏
对于已经不再被使用且已被回收的 ThreadLocal 对象，它在每个线程内对应的实例由于被
线程的 ThreadLocalMap 的 Entry 强引用，无法被回收，可能会造成内存泄漏。

针对该问题，ThreadLocalMap 的 set 方法中，通过 replaceStaleEntry 方法将所有键为
null 的 Entry 的值设置为 null，从而使得该值可被回收。另外，会在 rehash 方法中通
过 expungeStaleEntry 方法将键和值为 null 的 Entry 设置为 null 从而使得该 Entry
可被回收。通过这种方式，ThreadLocal 可防止内存泄漏。
#+BEGIN_SRC java
  private void set(ThreadLocal<?> key, Object value) {
    Entry[] tab = table;
    int len = tab.length;
    int i = key.threadLocalHashCode & (len-1);

    for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) {
      ThreadLocal<?> k = e.get();
      if (k == key) {
        e.value = value;
        return;
      }
      if (k == null) {
        replaceStaleEntry(key, value, i);
        return;
      }
    }
    tab[i] = new Entry(key, value);
    int sz = ++size;
    if (!cleanSomeSlots(i, sz) && sz >= threshold)
      rehash();
  }
#+END_SRC
***  适用场景
 1. 每个线程需要自己单独的实例
 2. 实例需要在多个方法中共享, 但是不希望被多个线程共享
** AbstractQueuedSynchronizer
*** ReentrantLock  可重入锁
https://mp.weixin.qq.com/s?__biz=MzU0OTk3ODQ3Ng==&mid=2247484094&idx=1&sn=b337161f934b1c27ff1f059350ef5e65&chksm=fba6eabdccd163abc8978b65e155d79a133f20ee8a5bff79a33ed20a050c2bd576581db69fe6&mpshare=1&scene=1&srcid=0608yIcfsyrDG1NIBSsF58jq%23rd
****  公平锁
#+BEGIN_SRC java
  protected final boolean tryAcquire(int acquires) {
      final Thread current = Thread.currentThread();
      int c = getState();
      if (c == 0) {
          if (!hasQueuedPredecessors()/*先判断 AQS 的等待队列里是不是有其他线程在排队*/ &&
              compareAndSetState(0, acquires)) {
              setExclusiveOwnerThread(current);
              return true;
          }
      }
      else if (current == getExclusiveOwnerThread()) {
          int nextc = c + acquires;
          if (nextc < 0)
              throw new Error("Maximum lock count exceeded");
          setState(nextc);
          return true;
      }
      return false;
  }
#+END_SRC

**** 非公平锁

*** ReentrantReadWriteLock 读写锁
适合读多写少的高并发场景, 类似 Eureka 等服务注册中心的服务注册表.
加读锁时, 其他线程可以并发读, 不能并发写; 加写锁时, 不能并发读写.
* 缓存
** 缓存穿透
1. 什么是缓存穿透?
   #+begin_example
   正常情况查询的数据都是存在的. 当查询一条压根儿数据库中根本就不存在的数据, 也
   就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去.  这种查
   询不存在的数据的查询就是*缓存穿透*
   #+end_example
2. 穿透带来的问题
   #+begin_example
   试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生
   大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。
   #+end_example
3. 解决办法
   - 缓存空值
     #+begin_example
     之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都
     到数据库去了。
     那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这
     个key 的请求的时候，直接返回null 。
     这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。
     #+end_example
   - BloomFilter
     #+begin_example
     在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是
     否存在，如果不存在就直接返回，存在再走查缓存 -> 查 DB。
     #+end_example
4. 使用场景
   - 针对异常 key 较多,请求重复率较低的数据,没有必要进行缓存,使用 BloomFilter 直接
     过滤掉
   - 对于有限的空数据的 key,重复率较高的,可以缓存空值解决
** 缓存击穿
1. 什么是缓存击穿?
   #+begin_example
   在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，
   就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。
   #+end_example
2. 击穿带来的问题
   #+begin_example
   某一时刻数据库请求量剧增
   #+end_example
3. 如何解决
   #+begin_example
    击穿现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的
   请求上使用一个 互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线
   程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。
   #+end_example
** 缓存雪崩
 1. 什么是缓存雪崩
    #+begin_example
    某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进
    来直接打到DB上面。结果就是DB 扛不住, 挂掉
    #+end_example
 2. 解决办法
    - 事前, 使用集群缓存, 保证缓存服务的高可用
    - 事中, ehcahe 本地缓存+Hystrix 限流&降级, 避免 MySQL 被打死
    - 事后, 开启 Redis 持久化机制, 尽快回复缓存集群
** 解决热点数据集中失效的问题
对于一些热点数据来说, 当缓存失效以后会有大量的请求打到数据库, 可能导致数据库崩溃
1. 设置不同的失效时间
2. 互斥锁
* MQ
| 特性                   | ActiveMQ        | RabbitMQ       | RocketMQ          | Kafka                 |
|------------------------+-----------------+----------------+-------------------+-----------------------|
| 单机吞吐               | 万              | 万             | 10 万             | 10 万,大数据系统      |
| topic 数量对吞吐的影响 | -               | -              | 几百到几千        | 几十到几百            |
| 时效性                 | ms              | um             | ms                | ms                    |
| 可用性                 | 主从架构,高可用 | 同 ActiveMQ    | 分布式架构,非常高 | 分分布式架构+副本机制 |
| 消息可靠性             | 较低概率丢数据  | 基本不丢       | 0 丢失            | 0 丢失                |
| 功能支持               | 完备            | 并发/性能/延时 | 完备              | 功能简单              |

** 为什么要引入消息中间件
 1. 系统解耦
 2. 复杂调用链路异步调用
 3. 流量削峰
** 引入消息中间件的缺点
 1. 系统可用性下降
 2. 系统稳定性下降
 3. 分布式一致性问题
** kafka 保证高可用
[[./images/kafka-after.png][kafka 保证高可用]]
** kafka 消息的可靠性传输
 1. 消费端自动提交 offset,未处理消息就宕机. 关闭自动提交 offset, 处理完消息后手
    动 offset
 2. kafka 丢失数据. follower 有数据未同步, 选举成为 leader 后导致消息丢失.
    - 设置=replication.factor=参数>1, 一般设 2 个副本
    - 设置=min.insync.replicas=参数>0, 一般设 1, leader 至少要感知到有 1 个
      follower 跟上自己的进度
    - producer 端设置=acks=all=, 写入所有 replica 后, 才认为写成功
    - producer 端设置=retries=MAX=, 一旦写入失败, 就无限重试
** kafka 保证消息的顺序性
 1. 一个 topic，一个 partition(partition 内是有序的)，一个 consumer，内部单线程
    消费，单线程吞吐量太低，一般不会用这个。
 2. 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线
    程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

** MQ 如何保证幂等性
1. 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，
   update 一下好吧。
2. 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
3. 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，
   里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根
   据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后
   这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
4. 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重
   复数据插入只会报错，不会导致数据库中出现脏数据。

