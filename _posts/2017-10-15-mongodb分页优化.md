---
layout: post
title: MongoDB分页优化
tags: MongoDB
category: 数据库
description: 
description: 
---


**[MongoDB 中数据分页优化技术](http://www.c-s-a.org.cn/ch/reader/create_pdf.aspx?file_no=20150647)**

**[MongoDB分页处理方案](http://blog.sina.com.cn/s/blog_56545fd30101442b.html)**

---

## 一. MongoDB分页现状

MongoDB在数据超过百万级后分页速度明显降低,从ms级到s级,到千万级后已经到无法忍受的速度了,下面有具体的实际分析
<!--more-->
<!--more-->

```json
无索引情况
[
    {
        "v" : 2.0, 
        "key" : {
            "_id" : 1.0
        }, 
        "name" : "_id_", 
        "ns" : "admin.DTO"
    }
]

数据量500万
====================================================================

*********
skip数量 : 3000010.0, 
db.DTO.explain("executionStats").find({}).sort({"createTime":-1}).skip(3000000).limit(10)
OperationFailed: Sort operation used more than the maximum 33554432 bytes of RAM

--------------------------------------------------------------------
--------------------------------------------------------------------

*********
skip数量 : 3000010.0, 
db.DTO.explain("executionStats").find({'_id':{$lte:ObjectId("59c550c416fa5c3e9c0e9709")}}).sort({"createTime":-1}).limit(10)
"nReturned" : 10.0, 
"executionTimeMillis" : 15330.0, 
"totalKeysExamined" : 2000001.0, 
"totalDocsExamined" : 2000001.0, 

--------------------------------------------------------------------
--------------------------------------------------------------------

*********
skip数量 : 3000010.0, 
db.DTO.explain("executionStats").find({'id':{$lte:NumberLong(2000001)}}).sort({"createTime":-1}).limit(10)
"nReturned" : 10.0, 
"executionTimeMillis" : 28718.0, 
"totalKeysExamined" : 0.0, 
"totalDocsExamined" : 5000001.0, 

====================================================================
```

```json
复合索引情况
[
    {
        "v" : 2.0, 
        "key" : {
            "_id" : 1.0
        }, 
        "name" : "_id_", 
        "ns" : "admin.DTO"
    }, 
    {
        "v" : 2.0, 
        "key" : {
            "id" : 1.0, 
            "createTime" : -1.0
        }, 
        "name" : "id_1_createTime_-1", 
        "ns" : "admin.DTO"
    }, 
    {
        "v" : 2.0, 
        "key" : {
            "idcard" : 1.0, 
            "createTime" : -1.0
        }, 
        "name" : "idcard_1_createTime_-1", 
        "ns" : "admin.DTO"
    }, 
    {
        "v" : 2.0, 
        "key" : {
            "name" : 1.0, 
            "createTime" : -1.0
        }, 
        "name" : "name_1_createTime_-1", 
        "ns" : "admin.DTO"
    }
]

数据量500万
====================================================================

*********
skip数量 : 3000010.0, 
db.DTO.explain("executionStats").find({}).sort({"createTime":-1}).skip(3000000).limit(10)
"nReturned" : 1.0, 
"executionTimeMillis" : 29573.0, 
"totalKeysExamined" : 0.0, 
"totalDocsExamined" : 5000001.0,

--------------------------------------------------------------------
--------------------------------------------------------------------

*********
skip数量 : 3000010.0, 
db.DTO.explain("executionStats").find({'_id':{$lte:ObjectId("59c550c416fa5c3e9c0e9709")}}).sort({"createTime":-1}).limit(10)
"nReturned" : 10.0, 
"executionTimeMillis" : 14568.0, 
"totalKeysExamined" : 2000001.0, 
"totalDocsExamined" : 2000001.0, 

--------------------------------------------------------------------
--------------------------------------------------------------------

*********
skip数量 : 3000010.0, 
db.DTO.explain("executionStats").find({'id':{$lte:NumberLong(2000001)}}).sort({"createTime":-1}).limit(10)
"nReturned" : 10.0, 
"executionTimeMillis" : 14756.0, 
"totalKeysExamined" : 2000001.0, 
"totalDocsExamined" : 2000001.0, 

====================================================================
```

## 二. MongoDB分页优化

下面是针对[MongoDB分页处理方案](http://blog.sina.com.cn/s/blog_56545fd30101442b.html)中第三条方案的实现

```Java
/**
 * 同步分页信息到redis
 * Created by zhuji on 2017/9/25.
 */

@Component
public class SynchroPaginationService {

    @Autowired
    private RedisComponent redisComponent;
    @Autowired
    private MongoDb<DTO> mongoDb;

    public void synchroPagination(PageInfo pageInfo) {
        redisComponent.initDataBaseIndex(6);

        long count = mongoDb.count(DTO.class, null);  //总数
        int pageSize = pageInfo.getPageSize();  //页大小
        int totalPage = (int) Math.floor((double) count / pageSize);    //总页数
        String direction = pageInfo.getDirection();     //排序方向  'DESC','ASC'

        LocalDateTime endTime = LocalDateTime.now();    //查询mongo第一页的时间条件

        //指定字段是否返回
        BasicDBObject fieldsObject = new BasicDBObject();
        fieldsObject.append("createTime", true);

        //====同步第0到count/pageSize页
        for (int i = 0; i <= totalPage; i++) {
            //查询条件
            BasicDBObject queryCondition = new BasicDBObject();
            Query query;
            switch (direction.toUpperCase()) {
                case "DESC":
                    queryCondition.put("createTime", new BasicDBObject("$lt", endTime));
                    query = new BasicQuery(queryCondition, fieldsObject)
                        .with(new Sort(Sort.Direction.DESC, "createTime"))
                        .limit(pageSize);
                    break;
                case "ASC":
                    queryCondition.put("createTime", new BasicDBObject("$gt", endTime));
                    query = new BasicQuery(queryCondition, fieldsObject)
                        .with(new Sort(Sort.Direction.ASC, "createTime"))
                        .limit(pageSize);
                    break;
                default:
                    query = new BasicQuery(queryCondition, fieldsObject)
                        .with(new Sort(Sort.Direction.DESC, "createTime"))
                        .limit(pageSize);//默认逆序
            }

            List<DTO> nextPage = mongoDb.find(query, DTO.class);
            redisComponent.setHashKey(Constant.CRM_PAGINATION_INFO_KEY, i, nextPage.get(0).getCreateTime());
            endTime = nextPage.get(pageSize - 1).getCreateTime();   //设置下一页查询条件
        }
    }
}
```

经测试同步100万数据(每页10条)分页信息到redis耗时3min,同步之后分页查询时间到10ms内,但是太耗资源未被采用.暂时参考[MongoDB分页处理方案](http://blog.sina.com.cn/s/blog_56545fd30101442b.html)中Google的处理方案吧.

redis辅助类

```java
public class RedisComponent {

    @Autowired
    //操作字符串的template, StringRedisTemplate是RedisTemplate的一个子集
    private StringRedisTemplate stringRedisTemplate;

    /**
     * 设置redis中hash值
     * @param hashKey   redis中的键    'pagination_info'
     * @param key       键hashKey对应的键值对的key  '1','2'
     * @param value     键hashKey对应的键值对的value    '[2017-09-25 12:00:02, 2017-09-25 12:00:03]'
     */
    public void setHashKey(String hashKey, Object key, Object value){
        stringRedisTemplate.boundHashOps(hashKey).put(JSON.toJSONString(key), JSON.toJSONString(value));
    }

    /**
     * 从redis中获取hashKey对应key的值
     * @param hashKey       redis中的键    'pagination_info'
     * @param key           键hashKey对应的键值对的key  '1','2'
     * @return              key对应的值value
     */
    public Object getHashKey(String hashKey, Object key){
        return stringRedisTemplate.boundHashOps(hashKey).get(JSON.toJSONString(key));
    }

    /**
     * 从Redis中获取唯一ID
     * @param index redis数据库号
     * @param key   redis中键 next_id
     * @param step  自增步长,默认1
     * @return      返回key的唯一ID
     */
    public Long getUniqueId(int index, String key, Long step){
        if (step == null) step = 1L;
        initDataBaseIndex(index);
        return stringRedisTemplate.opsForValue().increment(key, step);
    }

    /**
     * 设置Redis数据库号
     * @param index Redis数据库号
     */
    public void initDataBaseIndex(int index){
        ((JedisConnectionFactory) stringRedisTemplate.getConnectionFactory()).setDatabase(index);
    }

}
```

redis ID生成器的测试

```Java
/**
 * Created by zhuji on 2017/9/18.
 */

@RunWith(SpringJUnit4ClassRunner.class)
@SpringBootTest
public class RedisComponentTest {

    @Autowired
    private RedisComponent redisComponent;

    @Before
    public void init() {
//        redisComponent.initDataBaseIndex(5);
//        ((JedisConnectionFactory)redisComponent.getStringRedisTemplate().getConnectionFactory()).setDatabase(5);
    }

    @Test
    public void getUniqueId() throws Exception {
        int threadCount = 50;
        final int genCount = 100;
        StopWatch watch = new StopWatch();
        watch.start();

        // unique id check
        final Map<Long, Object> map = new ConcurrentHashMap<>();
        final Object o = new Object();

        CompletableFuture.allOf(IntStream.range(0, threadCount)
            .mapToObj(i -> CompletableFuture.runAsync(() -> test(genCount, map, o))).toArray(CompletableFuture[]::new))
            .get();

        watch.stop();

        System.out.println("threadCount:" + threadCount + ", genCount:" + genCount);
        System.out.println("map size:" + map.size());

        System.out.println("time:" + watch);
        System.out.println("speed:" + genCount * threadCount / (watch.getTotalTimeMillis() / 1000.0));

        if (map.size() != threadCount * genCount) {
            System.err.println("It seems generated the same id!!!");
            System.exit(-1);
        }

    }

    private void test(int genCount, Map<Long, Object> map, Object o) {

        IntStream.range(0, genCount)
            .forEach(j -> {
                Long nextId = redisComponent.getUniqueId(5, "CRM:next_id", 1L);
                System.out.println(nextId);
                map.put(nextId, o);
            });
    }

}
```