---
layout: post
title: 消息队列之kafka
tags: kafka
category: 消息队列
#eye_catch: http://jekyllrb.com/img/logo-2x.png
---


**[kafka 学习参考](http://www.orchome.com/66)**

Kafka拓扑结构
![](http://cdn3.infoqstatic.com/statics_s1_20170913-0458/resource/articles/kafka-analysis-part-1/zh/resources/0310020.png)

一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View, 或者是服务器日志, 系统CPU、Memory等）, 若干broker（Kafka支持水平扩展, 一般broker数量越多, 集群吞吐率越高）, 若干Consumer Group, 以及一个Zookeeper集群.Kafka通过Zookeeper管理集群配置, 选举leader, 以及在Consumer Group发生变化时进行rebalance.Producer使用push模式将消息发布到broker, Consumer使用pull模式从broker订阅并消费消息.

---
<!--more-->
<!--more-->

## 一. 启动zookeeper和server端(单节点)
终端启动zookeeper,port默认2181

`--- ~ » cd kafka`

`--- ~/kafka » bin/zookeeper-server-start.sh config/zookeeper.properties`

终端启动kafka server端,port默认9092

`--- ~ » cd kafka`

`--- ~/kafka » bin/kafka-server-start.sh config/server.properties`

---
启动多节点

`--- ~ » cd kafka`

`--- ~/kafka » cp config/server.properties config/server-1.properties`

`--- ~/kafka » cp config/server.properties config/server-2.properties`

修改server-1.properties

```
broker.id=1	//唯一id
listeners=PLAINTEXT://:9093	
log.dirs=/tmp/kafka-logs-1		//日志目录
```

修改server-2.properties

```
broker.id=2	//唯一id The id of the broker
listeners=PLAINTEXT://:9094	//The address the socket server listens on
log.dirs=/tmp/kafka-logs-2		//日志目录A comma seperated list of directories under which to store log files
num.partitions=2	//The default number of log partitions per topic. More partitions allow greater parallelism for consumption, but this will also result in more files across the brokers.
```

`--- ~/kafka » bin/kafka-server-start.sh config/server-1.properties`

`--- ~/kafka » bin/kafka-server-start.sh config/server-2.properties`


---

## 二. springboot中使用示例
kafka依赖

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
    <version>1.2.2.RELEASE</version>
</dependency>
```

gradle
`compile group: 'org.springframework.kafka', name: 'spring-kafka', version: '1.2.2.RELEASE'`

yml配置

```yml
spring:
  kafka:
    template:
      default-topic: test #默认主题
#   consumer配置
    consumer:
      bootstrap-servers: localhost:9092
      group-id: testSystem  #分组id
      enable-auto-commit: false
      auto-offset-reset: earliest
#   producer配置
    producer:
      bootstrap-servers: localhost:9092
```

### 生产者示例

```java
@Component
public class KafkaProducer{
    private static final Logger logger = LoggerFactory.getLogger(KafkaProducer.class);

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    public void produceMessage(String topic, String key, Object value) {
        String defaultTopic = kafkaTemplate.getDefaultTopic();
        logger.info("=====kafka 默认主题=======" + defaultTopic);
//        kafkaTemplate.sendDefault("00000201707127785", "{\"status\":\"013010\",\"loanNo\":\"00000201707127785\",\"statusChangeTime\":\"2017-09-08 15:30:16\"}");
        kafkaTemplate.send(topic, key, JSON.toJSONString(value));
    }
}
```



### 消费者示例

```java
@Component
public class KafkaConsumer {

    private static final Logger logger = LoggerFactory.getLogger(KafkaConsumer.class);

    @KafkaListener(topics = "${spring.kafka.template.default-topic}")	//订阅主题(yml中指定的default-topic)
    @KafkaHandler   //指明消息接收处理方法
    public void processMessage(ConsumerRecord<String, String> record) {
        try {
            logger.info("=============kafkaConsumer开始消费=============");
            String topic = record.topic();
            String key = record.key();
            String value = record.value();
            long offset = record.offset();
            int partition = record.partition();
            logger.info("-------------topic:" + topic);
            logger.info("-------------value:" + value);
            logger.info("-------------key:" + key);
            logger.info("-------------offset:" + offset);	//偏移量,客户端自己控制的
            logger.info("-------------partition:" + partition);	//分区,可在server.properties中或在创建主题时设置数量,默认1
            //TODO 业务处理方法
            logger.info("~~~~~~~~~~~~~kafkaConsumer消费结束~~~~~~~~~~~~~");
        } catch (Exception e) {
            logger.error("==kafkaConsumer消费失败==, 消息--->" + record.value(), e);
        }
    }
}
```
